{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IgdHnzSnzZs2"
   },
   "source": [
    "\n",
    "# Exercise 1.2\n",
    "## Classification of MNIST digits with a fully-connected neural network\n",
    "\n",
    "In this exercise we will classify [MNIST digits](https://en.wikipedia.org/wiki/MNIST_database) using a fully-connected neural network\n",
    "\n",
    "## Part 1: Using a Jupyter notebook on HPC\n",
    "If you are reading this, you probably already managed to open the Jupyter notebook on HPC -- if not, try to do that before doing the exercise.\n",
    "We start by importing the modules that we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n6YTUAAlzZs5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sOeRq_xHzZtC"
   },
   "source": [
    "We check that we have a GPU available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eRKroSgizZtC"
   },
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(\"The code will run on GPU.\")\n",
    "else:\n",
    "    print(\"The code will run on CPU. Go to Edit->Notebook Settings and choose GPU as the hardware accelerator\")\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hf5kG-RszZtG"
   },
   "source": [
    "The MNIST dataset is a built-in dataset in PyTorch (it is a very common dataset to test algorithms on). \n",
    "\n",
    "We import it, and set our minibatch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lzZHxNsgzZtH"
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "trainset = datasets.MNIST('./data', train=True, download=True, transform=transforms.ToTensor())\n",
    "train_loader = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=1)\n",
    "testset = datasets.MNIST('./data', train=False, download=True, transform=transforms.ToTensor())\n",
    "test_loader = DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7xoF9GRL25jq"
   },
   "source": [
    "First, we plot the images to get an idea of what data we're working with. MNIST images are $28\\times28$ images of handwritten digits (0-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mjeITqYf1itt"
   },
   "outputs": [],
   "source": [
    "images, labels = next(iter(train_loader))\n",
    "plt.figure(figsize=(20,10))\n",
    "\n",
    "for i in range(21):\n",
    "    plt.subplot(5,7,i+1)\n",
    "    plt.imshow(images[i].numpy()[0], 'gray')\n",
    "    plt.title(labels[i].item())\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hGuvRy0zzZtP"
   },
   "source": [
    "You should implement a fully-connected network to classify the digits. It should contain 1 hidden layer with 100 units. Don't forget the ReLU activation function after the hidden layer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kkWvoY__zZtQ"
   },
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Network, self).__init__()\n",
    "        self.fully_connected1 = nn.Sequential(\n",
    "            ...,\n",
    "            ...,\n",
    "            )\n",
    "        \n",
    "        self.fully_connected2 = nn.Sequential(\n",
    "            nn.Linear(100,10),\n",
    "            nn.Softmax(dim = 1)\n",
    "            )\n",
    "        \n",
    "    def forward(self, x):\n",
    "      #reshaping x so it becomes flat, except for the first dimension (which is the minibatch)\n",
    "        x = x.view(x.size(0),-1)\n",
    "        x = self.fully_connected1(x)\n",
    "        x = self.fully_connected2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_i2qWBsNzZtU"
   },
   "source": [
    "We instantiate a copy of our network and transfer it to the GPU if it's available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VJVToX8hzZtV"
   },
   "outputs": [],
   "source": [
    "model = Network()\n",
    "model.to(device)\n",
    "#Initialize the optimer\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ky-KOYBA3i4R"
   },
   "source": [
    "We train the network for five epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YEQU9cIVzZth"
   },
   "outputs": [],
   "source": [
    "num_epochs = 5\n",
    "\n",
    "for epoch in tqdm(range(num_epochs), unit='epoch'):\n",
    "    #For each epoch\n",
    "    train_correct = 0\n",
    "    for minibatch_no, (data, target) in tqdm(enumerate(train_loader), total=len(train_loader)):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        #Zero the gradients computed for each weight\n",
    "        optimizer.zero_grad()\n",
    "        #Forward pass your image through the network\n",
    "        output = model(data)\n",
    "        #Compute the loss\n",
    "        loss = F.nll_loss(torch.log(output), target)\n",
    "        #Backward pass through the network\n",
    "        loss.backward()\n",
    "        #Update the weights\n",
    "        optimizer.step()\n",
    "        \n",
    "        #Compute how many were correctly classified\n",
    "        predicted = output.argmax(1)\n",
    "        train_correct += (target==predicted).sum().cpu().item()\n",
    "    #Comput the test accuracy\n",
    "    test_correct = 0\n",
    "    for data, target in test_loader:\n",
    "        data = data.to(device)\n",
    "        with torch.no_grad():\n",
    "            output = model(data)\n",
    "        predicted = output.argmax(1).cpu()\n",
    "        test_correct += (target==predicted).sum().item()\n",
    "    train_acc = train_correct/len(trainset)\n",
    "    test_acc = test_correct/len(testset)\n",
    "    print(\"Accuracy train: {train:.1f}%\\t test: {test:.1f}%\".format(test=100*test_acc, train=100*train_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rq---Q6xzZtl"
   },
   "source": [
    "You should now have a model that has about 96% accuracy on the test set.\n",
    "Try to get an even better accuracy. You can\n",
    "* Change the number of hidden layers\n",
    "* Change the number of units in the hidden layers\n",
    "* Try changing the learning rate by factors of 10. What happens if it is too high or too low?\n",
    "* Try using sigmoid instead of ReLU activation. What happens?\n",
    "\n",
    "How large accuracy can you get?\n",
    "\n",
    "Try showing the classification output (probabilities) from the model alongside the ground truth.\n",
    "\n",
    "* Which are classified correctly/incorrectly? \n",
    "* If it's incorrect, what is the second most likely class?\n",
    "* Do the misclassifications you see make sense? Why/why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Running code in the terminal\n",
    "Next, implement the classifier from this Jupyter notebook in a (reasonably clean) python script and train it from a terminal on HPC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Exercise 1.1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
